\documentclass[letterpaper]{article}
\input{../../../preamble.tex}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{fancyhdr}
\usepackage[hidelinks]{hyperref}

\pagestyle{fancy}
\fancyhf{}
\rhead{Math 103B}
\chead{Friday, January 28, 2022}
\lhead{Lecture 11}
\rfoot{\thepage}

\setlength{\parindent}{0pt}

\begin{document}

\section{Division with Remainders}
Recall that if $a, b \in \Z$ with $b \neq 0$, then there exists unique integers $q, r \in \Z$ with $0 \leq r < |b|$ such that:
\[a = bq + r\]
As a consequence, we note that: 
\[\Z / n \Z = \{\underbrace{0, 1, \dots, n - 1}_{\text{Possible Remainders}}\}\]
If $a \in \Z$, then:
\[a = nq + r \equiv r \Mod{n}\]
The uniqueness of $r$ in $[0, n]$ implies the equivalence classes $0, 1, \dots, n - 1$ are distinct. 

\subsection{Division Theorem over a Field}
\begin{theorem}{}{}
    Let $F$ be a field and $f(x), g(x) \in \F[x]$ with $g(x) \neq 0$. Then, there exists unique polynomials $q(x)$ and $r(x) \in \F[x]$ such that $f(x) = g(x) q(x) + r(x)$ and $\deg r(x) < \deg g(x)$, including $r(x) = 0$. 
\end{theorem}
\textbf{Remark:} This is essentially the end result of polynomial long division. 

\subsubsection{Example 1: Polynomial Division}
Consider $f(x) = x^6 + x$ and $g(x) = x^2 + 1$ where $f, g \idotsint \F_{3}[x]$. Then, we have: 
\[\frac{f(x)}{g(x)} = 1x^4 - x^2 + 1\]
With the remainder being $x - 1$. Therefore, the final answer is: 
\[x^6 + x = (x^2 + 1)(x^4 - x^2 + 1) + (x - 1)\]
\textbf{Remark:} Since $\F_{3} = \{0, 1, 2\} \Mod{3}$, we \emph{can} change the negative numbers to the corresponding numbers in $\F_{3}$. So, we could write the above like so: 
\[x^6 + x = (x^2 + 1)(x^4 + 2x^2 + 1) + (x + 2)\]
Where $-1 \equiv 2 \Mod{3}$. 

\subsection{Consequences}
If $\deg f(x) = n$, then: 
\[\frac{\F[x]}{\cyclic{f(x)}} = \{\overbrace{a_0 + a_1 x + a_2 x^2 + \dots + a_{n - 1} x^{n - 1}}^{\text{Possible Remainders}} + \cyclic{f(x)}\}\]
Since the remainders are unique, each of these cosets are distinct. 

\begin{itemize}
    \item If $\deg f(x) = 1$, so $f(x) = ax + b$ ($a \neq 0$), then: 
    \[\frac{\F[x]}{\cyclic{ax + b}} = \{a_0 + \cyclic{f(x)}\} \xrightarrow{\sim} \F\]
    Where $a_0$ is a constant. So:
    \[a_0 + \cyclic{f(x)} \mapsto a_0\]

    \item If $\deg f(x) = 2$, then: 
    \[\frac{\F[x]}{\cyclic{f(x)}} = \{a + bx + \cyclic{f(x)}\}\]
    Recall that: 
    \[\frac{\R[x]}{\cyclic{x^2 + 1}} = \{a + bx + \cyclic{x^2 + 1}\} \cong \C\]
    \[a + bx \mapsto a + bi\]

    \item If $\deg f(x) = 0$, then: 
    \[\frac{\F[x]}{\cyclic{f(x)}} = \{0 + \cyclic{f(x)}\} \cong \{0\}\]
    This is because $\deg r(x) < \deg f(x) = 0$, so it follows that the possible remainders are none. 
\end{itemize}

\subsection{Proof of Division Theorem}
\begin{mdframed}[]
    \begin{proof}
        We need to show two things. Let $f(x), g(x) \in \F[x]$ with $g(x) \neq 0$.
        \begin{itemize}
            \item \underline{Existence:} We use proof by induction. 
            \begin{itemize}
                \item \underline{Base Case:} If $\deg f(x) < \deg g(x)$, then $f(x) = g(x) \cdot 0 + f(x)$ so we can choose $q(x) = 0$ and $r(x) = f(x)$. 
                \item \underline{Inductive Step:} Assume $q, r$ exist for all polynomial $f$ of degree $\deg f(x) < n$. If $\deg f(x) = n \geq m = \deg g(x)$, then we write 
                \[f(x) = a_0 + a_1 x + \dots + a_n x^n\]
                with $a_n \neq 0$ and
                \[g(x) = b_0 + b_1 x + \dots + b_m x^m\]
                with $b_m \neq 0$. We set 
                \[f_{1}(x) = f(x) - a_n b_{m}^{-1} x^{n - m} g(x)\]
                so by construction, the $x^n$-terms cancel out and $\deg f_{1}(x) \leq n - 1 < n$. By the inductive hypothesis, there exists a $q_{1}(x), r_{1}(x) \in \F[x]$ such that
                \[f_{1}(x) = g(x)q(x) + r_{1}(x)\]
                and 
                \[\deg r_{1}(x) < \deg g(x)\]
                which implies that 
                \[f(x) - a_{n}b_{m}^{-1} x^{n - m} g(x) = g(x) q_{1}(x) + r_{1}(x)\]
                which further implies that 
                \[f(x) = g(x)(a_n b_{m}^{-1} x^{n - m} + q_{1}(x)) + r_{1}(x)\]
                with $\deg r_{1}(x) < \deg g(x)$. So, take $q(x) = a_n b_{m}^{-1} x^{n - m} + q(x)$ and $r(x) = r_{1}(x)$ and we are done. 
            \end{itemize}

            \item \underline{Uniqueness:} Suppose $f(x) = g(x) q(x) + r(x) = g(x) \overline{q}(x) + \overline{r}(x)$ with $\deg r(x), \deg \overline{r}(x) < \deg g(x)$. Then, subtracting the two equation gives us: 
            \begin{equation*}
                \begin{aligned}
                    0 &= (g(x)q(x) + r(x)) - (g(x) \overline{q}(x) + \overline{r}(x)) \\ 
                        &\implies \overline{r}(x) - r(x) = g(x)(q(x) - \overline{q}(x))
                \end{aligned}
            \end{equation*}
            Suppose, towards a contradiction, that $q(x) \neq \overline{q}(x)$. Then, $q(x) - \overline{q}(x) \neq 0$ so $\deg (q(x) - \overline{q}(x)) \geq 0$, thus 
            \[\deg (g(x)(q(x) - \overline{q}(x))) = \deg g(x) + \deg (q(x) - \overline{q})(x) \geq \deg g(x)\]
            However, note that 
            \[\deg r(x), \deg \overline{r}(x) < \deg g(x)\]
            which implies that 
            \[\deg(\overline{r}(x) - r(x)) \leq \max\{\deg r(x), \deg \overline{r}(x)\} < \deg g(x)\]
            But this is a contradiction. Thus, $q(x) = \overline{q}(x)$ and $\overline{r}(x) - r(x) = 0$, so $\overline{r}(x) = r(x)$. 
        \end{itemize}
        This concludes the proof.
    \end{proof}
\end{mdframed}


\subsection{More Properties}
\begin{definition}{}{}
    We say $g(x)$ \textbf{divides} $f(x)$, and write $g(x) | f(x)$, if $f(x) = g(x) q(x)$, i.e. has remainder 0. We say that $g(x)$ is a \textbf{factor} of $f(x)$.
\end{definition}

\begin{definition}{}{}
    A \textbf{zero} or \textbf{root} of $f(x)$ is some $a \in \F$ such that $f(a) = 0$ for some $a$. 
\end{definition}

\begin{definition}{}{}
    The \textbf{multiplicity} of a root $a$ of $f(x)$ is the largest value of $k \in \Z_{\geq 0}$ such that $(x - a)^k | f(x)$. 
\end{definition}

\begin{corollary}{}{}
    Let $\F$ be a field, $a \in \F$, and $f(x) \in \F[x]$. Then, $f(a)$ is the remainder in the division of $f(x)$ by $x - a$. 
\end{corollary}

\begin{mdframed}[]
    \begin{proof}
        Write $f(x) = q(x)(x - a) + r(x)$ for $\deg r(x) < \deg (x - a) = 1$. This implies that $r(x)$ is constant. Plug in $x = a$ to get $f(a) = q(a) (\underbrace{a - a}_{0}) + r(a) = r(a)$. Then, $r(a) = f(a)$ and $r(x)$ is constant implies that $r(x) = f(a)$. 
    \end{proof}
\end{mdframed}

\begin{corollary}{}{}
    $f(a) = 0$ if and only if $(x - a) | f(x)$. 
\end{corollary}


\end{document}